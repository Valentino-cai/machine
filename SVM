main 函数
  导入数据
  使用SMO函数,得到参数b和α
  


SMO(dataset,labelset,c,toler,maxinter,ktup)SMO算法函数  
dataset labelset分别是输入和输出的list，c是凸二次规划参数（？）,toler容忍度,maxinter循环次数,ktup指定的核方式
  利用Optstruct函数,得到初始化结构体OS
  开始循环
    如果循环次数大于要求的最大循环次数,或者对阿尔法没有优化那么就终止循环
    第一次循环需要进行全局遍历for i in os.m
      利用InnerL函数来叠加计算α的变化    
 
定义结构体的目的是为了用于缓存，提高速度
class Optstruct:
  在这个类中要将dataset和labelset转换成合适的矩阵形式
  设定惩罚参数C  （惩罚参数C表示对噪声的容忍程度，C增大，容忍变低，需要优化，所有的拉格朗日乘子都被约束在以C为变成的矩形中）
  还需要设置容忍度，拉格朗日乘子α，偏置项b,以及预测值eCache,矩阵的列数m,以及核转换矩阵K,最后还要利用函数kernelTrans完成核函数结果的计算
  
kernelTrans（dataMat,rowdataMat,ktup）  rowdataMat 就是dataset中的某一行，之后转置完成结果的计算
  若ktup的值为'lin'则为线性核 
  若ktup的值为'rbf'则为高斯核(对高斯核的导入，第二个参数是高斯核的带宽)
  根据传入的ktup的值不同,返回不同的核函数的结果(此时返回的结果仅仅是一列)
  
 InnerL(i,OS)
  利用CalEK函数计算预测误差EK
  如果当前的i得到的α违背KKT条件，则 
      使用SelectJ进行第二个α的选择  得到行的序号j和误差Ej
      在数学上根据标签分类的异同，对α2（α1）的上下界有了限定
      如果内核分母小于等于0，则return                    ###在数学上经过求导得到的最后的优化目标为二次函数的最小值
                                                                     k11+k22-2k12是二次项的系数 称为内核分母
                                                                     如果该值为0，则最小值出现在边缘，如果该值<0,则在边缘取得最小值，
                                                                      如果大于0，则在H,L
  否则，return 0
  
 CalEk(OS,i) 预测误差计算函数  i为行索引
  计算当前参数下datamat得到的函数值
  将当前函数值与labelmat对比，得到误差
 
 SelectJ(i,OS,EK)α获取函数，第一次随机选取，之后选择和i的误差EK最大的j   返回j和j对应的误差Ej
  利用EK对OS中的误差变量eCache进行修改
  读入OS.eCache中缓存与[0]的数据
  若读入的数据长度大于1,说明存在误差项，并非第一次，需要改进
    对其中的每一个非零值重新计算误差
    找到和EK相差最大的那个位置（行数）
    
  若长度小于1
    那么随机选择一个j 
    计算j行数据的误差
    
